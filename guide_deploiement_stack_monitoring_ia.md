# ğŸ› ï¸ Guide de DÃ©ploiement : Stack Monitoring & ObservabilitÃ© IA

## ğŸ“¦ Contenu de la stack

Cette stack open source permet de superviser et observer les mÃ©triques, logs et traces d'un modÃ¨le IA en production.

### Services inclus :
- **Prometheus** â€“ collecte et exposition des mÃ©triques
- **Grafana** â€“ visualisation et tableaux de bord
- **Loki** â€“ agrÃ©gation de logs
- **OpenTelemetry Collector** â€“ collecte et envoi de mÃ©triques
- *(+ fichiers de configuration adaptÃ©s)*

## âœ… PrÃ©requis

- Docker & Docker Compose installÃ©s
- Ports disponibles : `3000`, `9090`, `3100`, `8889`
- Dossier local contenant les fichiers de configuration (`ai_monitoring_stack.zip` dÃ©compressÃ©)

## ğŸš€ Ã‰tapes de dÃ©ploiement

### 1. ğŸ“ Cloner ou extraire le rÃ©pertoire

```bash
unzip ai_monitoring_stack.zip
cd ai-monitoring-stack
```

Arborescence attendue :
```
.
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ loki/
â”‚   â””â”€â”€ local-config.yaml
â””â”€â”€ otel/
    â””â”€â”€ otel-collector-config.yaml
```

### 2. ğŸ§± Lancer la stack

```bash
docker-compose up -d
```

Cela dÃ©marre les 4 services :
- `grafana` sur [http://localhost:3000](http://localhost:3000)
- `prometheus` sur [http://localhost:9090](http://localhost:9090)
- `loki` sur [http://localhost:3100](http://localhost:3100)

### 3. ğŸ” Connexion Ã  Grafana

- AccÃ©der Ã  [http://localhost:3000](http://localhost:3000)
- Identifiants :
  - **Utilisateur** : `admin`
  - **Mot de passe** : `admin`

âš ï¸ Changez le mot de passe Ã  la premiÃ¨re connexion.

### 4. â• Ajouter les sources de donnÃ©es dans Grafana

Dans lâ€™interface Grafana :
- Ajouter une source Prometheus : `http://prometheus:9090`
- Ajouter une source Loki : `http://loki:3100`

### 5. ğŸ“Š CrÃ©er vos premiers dashboards

- Utilisez les labels exposÃ©s par OpenTelemetry ou ajoutez des dashboards standards pour visualiser :
  - Latence, erreurs, appels IA
  - Logs applicatifs, dÃ©rives, exceptions
  - Charge CPU/RAM du modÃ¨le IA

### 6. âš™ï¸ Exposer vos modÃ¨les IA au monitoring

Ajoutez Ã  votre code Python :

```python
from prometheus_client import Counter, start_http_server

inference_counter = Counter('model_inferences_total', 'Nombre dâ€™infÃ©rences IA')
start_http_server(8000)

# Dans votre fonction dâ€™infÃ©rence
inference_counter.inc()
```

Puis ajoutez ce port comme target dans `prometheus.yml`.

## ğŸ”’ Bonus sÃ©curitÃ©

- Activez HTTPS sur Grafana avec un reverse proxy (NGINX, Traefik)
- Restreignez lâ€™accÃ¨s par IP ou via authentification OIDC
- Connectez Ã  un systÃ¨me de logs centralisÃ© si besoin (SIEM, ELK)

## ğŸ“š Ressources complÃ©mentaires

- [Grafana Loki Documentation](https://grafana.com/docs/loki/)
- [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/)
- [ML Monitoring avec Prometheus](https://prometheus.io/docs/introduction/overview/)
